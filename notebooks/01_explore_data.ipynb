{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3e4b748",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing imports...\n",
      "‚úÖ All imports successful!\n",
      "Connecting to Ollama...\n",
      "ü§ñ AI says: Hello, Date Night AI is working!\n",
      "Testing movie food pairing...\n",
      "üçï Pairing suggestion:\n",
      "Pairing suggestion for \"The Godfather\":\n",
      "\n",
      "**Food:** Grilled Veal Chops\n",
      "**Drink:** 1960s-style Italian red wine (e.g. Barolo or Barbera)\n",
      "**Reason:** The rich, savory flavors of the veal and bold, full-bodied wine evoke the opulence and sophistication of Don Vito Corleone's world, mirroring the film's themes of power, loyalty, and tradition.\n",
      "Testing ChromaDB...\n",
      "‚úÖ ChromaDB working! Found: [['Italian food goes great with crime movies']]\n",
      "\n",
      "üéâ ================================== üéâ\n",
      "   ALL SYSTEMS WORKING!\n",
      "\n",
      "   ‚úÖ LangChain - Ready\n",
      "   ‚úÖ Ollama LLM - Connected  \n",
      "   ‚úÖ ChromaDB - Working\n",
      "\n",
      "   You're ready to build the RAG system!\n",
      "üéâ ================================== üéâ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is a Python file version - we'll convert to notebook\n",
    "\n",
    "# Run each section separately to test\n",
    "\n",
    "#%% [markdown]\n",
    "# # üé¨ Date Night AI - Testing Our Setup\n",
    "# Let's verify everything is working!\n",
    "\n",
    "#%% \n",
    "# Cell 1: Test Imports\n",
    "print(\"Testing imports...\")\n",
    "\n",
    "# Updated imports for newer LangChain versions\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import PromptTemplate  # Changed from langchain.prompts\n",
    "import chromadb\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "\n",
    "#%%\n",
    "# Cell 2: Test Ollama Connection\n",
    "print(\"Connecting to Ollama...\")\n",
    "\n",
    "llm = Ollama(model=\"llama3\")  # or \"llama3.2:1b\" if you used smaller model\n",
    "response = llm.invoke(\"Say 'Hello, Date Night AI is working!' and nothing else.\")\n",
    "print(f\"ü§ñ AI says: {response}\")\n",
    "\n",
    "#%%\n",
    "# Cell 3: Test Movie Food Pairing (Simple)\n",
    "print(\"Testing movie food pairing...\")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"movie\"],\n",
    "    template=\"\"\"You are a food pairing expert. \n",
    "    \n",
    "For the movie \"{movie}\", suggest ONE perfect food and drink pairing.\n",
    "Keep your response brief - just the food, drink, and a one-sentence reason.\n",
    "\n",
    "Response:\"\"\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"movie\": \"The Godfather\"})\n",
    "print(f\"üçï Pairing suggestion:\\n{response}\")\n",
    "\n",
    "#%%\n",
    "# Cell 4: Test ChromaDB (Vector Database)\n",
    "print(\"Testing ChromaDB...\")\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Changed: get_or_create instead of create\n",
    "# This way it won't error if collection already exists\n",
    "collection = client.get_or_create_collection(\"test_collection\")\n",
    "\n",
    "# Add some test data\n",
    "collection.add(\n",
    "    documents=[\"Italian food goes great with crime movies\", \n",
    "               \"Japanese food pairs well with anime\",\n",
    "               \"Mexican food is perfect for action movies\"],\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\"]\n",
    ")\n",
    "\n",
    "# Search for similar documents\n",
    "results = collection.query(\n",
    "    query_texts=[\"What food for a mafia movie?\"],\n",
    "    n_results=1\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ChromaDB working! Found: {results['documents']}\")\n",
    "\n",
    "#%%\n",
    "# Cell 5: All Tests Passed!\n",
    "print(\"\"\"\n",
    "üéâ ================================== üéâ\n",
    "   ALL SYSTEMS WORKING!\n",
    "   \n",
    "   ‚úÖ LangChain - Ready\n",
    "   ‚úÖ Ollama LLM - Connected  \n",
    "   ‚úÖ ChromaDB - Working\n",
    "   \n",
    "   You're ready to build the RAG system!\n",
    "üéâ ================================== üéâ\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c04a71-b8f5-45f9-adea-74a4ff3e5599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
